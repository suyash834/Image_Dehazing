{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c206fa1-4161-4a38-80c0-49399d02405f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "928506d6-00aa-460e-a978-32dd7537d36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drive_results_path = \"results_4\"\n",
    "os.makedirs(drive_results_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba0248f0-8320-4ac3-a6d3-519d0655968f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\ipg 3\\IOP2025\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd090626-205c-4754-baec-246dfb68d012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hazy images found: 547\n",
      "Clean images found: 547\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "\n",
    "hazy_dir = \"hazy\"\n",
    "clean_dir = \"clear\"\n",
    "\n",
    "hazy_paths = sorted(glob.glob(os.path.join(hazy_dir, \"*.*\")))\n",
    "clean_paths = sorted(glob.glob(os.path.join(clean_dir, \"*.*\")))\n",
    "\n",
    "print(\"Hazy images found:\", len(hazy_paths))\n",
    "print(\"Clean images found:\", len(clean_paths))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d1aec4c-da1e-4eb8-ac3f-882fe3774fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence-paired\n",
    "hazy_paths = sorted(glob.glob(os.path.join(hazy_dir, \"*\")))\n",
    "clean_paths = sorted(glob.glob(os.path.join(clean_dir, \"*\")))\n",
    "assert len(hazy_paths) == len(clean_paths), \"Mismatched hazy and clean images\"\n",
    "\n",
    "pairs = list(zip(hazy_paths, clean_paths))\n",
    "random.shuffle(pairs)\n",
    "split = int(0.8 * len(pairs))\n",
    "train_pairs = pairs[:split]\n",
    "test_pairs = pairs[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4d5ddf-29ea-48c1-b23b-c448d05d90d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DehazingDataset(Dataset):\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = pairs\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "    def __len__(self): return len(self.pairs)\n",
    "    def __getitem__(self, idx):\n",
    "        hazy_path, clean_path = self.pairs[idx]\n",
    "        hazy = Image.open(hazy_path).convert(\"RGB\")\n",
    "        clean = Image.open(clean_path).convert(\"RGB\")\n",
    "        return self.transform(hazy), self.transform(clean), hazy_path, clean_path\n",
    "\n",
    "train_loader = DataLoader(DehazingDataset(train_pairs), batch_size=4, shuffle=True)\n",
    "test_loader = DataLoader(DehazingDataset(test_pairs), batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f1c06be1-d6da-427f-a7bb-bf51f346b4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepDehazeNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        def conv_block(in_c, out_c):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, 3, padding=1),\n",
    "                nn.BatchNorm2d(out_c),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "\n",
    "        self.enc1 = conv_block(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.bottleneck = conv_block(64, 128)\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, 2, stride=2)\n",
    "        self.dec1 = conv_block(128, 64)\n",
    "        self.final = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        b = self.bottleneck(self.pool1(e1))\n",
    "        d1 = self.dec1(torch.cat([self.up1(b), e1], 1))\n",
    "        return torch.sigmoid(self.final(d1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7fc0b64-4c96-4718-8756-87f4df3d955f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss=0.0218, Test Loss=0.0135, PSNR=20.80, SSIM=0.77\n",
      "Epoch 2: Train Loss=0.0148, Test Loss=0.0121, PSNR=21.13, SSIM=0.82\n",
      "Epoch 3: Train Loss=0.0137, Test Loss=0.0114, PSNR=21.77, SSIM=0.84\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "\n",
    "# === SETUP ===\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepDehazeNet().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# === RESULT DIRECTORY ===\n",
    "drive_results_path = \"results_4\"\n",
    "os.makedirs(drive_results_path, exist_ok=True)\n",
    "\n",
    "# === TRAINING SETUP ===\n",
    "train_losses, test_losses, psnrs ,ssims = [], [], [], []\n",
    "best_psnr, overfit_epoch = 0, 0\n",
    "early_stop_counter = 0\n",
    "patience = 20\n",
    "num_epochs = 200\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for hazy, clean, *_ in train_loader:\n",
    "        hazy, clean = hazy.to(device), clean.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(hazy)\n",
    "        loss = criterion(output, clean)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_train_loss += loss.item()\n",
    "    train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Evaluate on test\n",
    "    model.eval()\n",
    "    total_test_loss = 0\n",
    "    total_psnr = 0\n",
    "    total_ssim =0\n",
    "    with torch.no_grad():\n",
    "        for hazy, clean, *_ in test_loader:\n",
    "            hazy, clean = hazy.to(device), clean.to(device)\n",
    "            output = model(hazy)\n",
    "            total_test_loss += criterion(output, clean).item()\n",
    "            psnr = compare_psnr(clean.cpu().numpy(), output.cpu().numpy(), data_range=1.0)\n",
    "            ssim = compare_ssim(\n",
    "                clean.cpu().squeeze().permute(1,2,0).numpy(),\n",
    "                output.cpu().squeeze().permute(1,2,0).numpy(),\n",
    "                channel_axis=-1, data_range=1.0\n",
    "            )\n",
    "            total_psnr += psnr\n",
    "            total_ssim += ssim\n",
    "    test_loss = total_test_loss / len(test_loader)\n",
    "    psnr_avg = total_psnr / len(test_loader)\n",
    "    avg_ssim = total_ssim / len(test_loader)\n",
    "    test_losses.append(test_loss)\n",
    "    psnrs.append(psnr_avg)\n",
    "    ssims.append(avg_ssim)\n",
    "\n",
    "    if psnr_avg > best_psnr:\n",
    "        best_psnr = psnr_avg\n",
    "        overfit_epoch = epoch\n",
    "        torch.save(model.state_dict(),\"best_model_4_4.pth\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "\n",
    "    print(f\"Epoch {epoch+1}: Train Loss={train_loss:.4f}, Test Loss={test_loss:.4f}, PSNR={psnr_avg:.2f}, SSIM={avg_ssim:.2f}\")\n",
    "    if early_stop_counter >= patience:\n",
    "        print(f\"Early stopping at epoch {epoch+1}\")\n",
    "        break\n",
    "\n",
    "# Final model\n",
    "torch.save(model.state_dict(),\"final_model_4_4.pth\")\n",
    "\n",
    "# === LOSS PLOT ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses, label='Train Loss' ,alpha=0.7)\n",
    "plt.plot(test_losses, label='Test Loss' ,alpha=0.7)\n",
    "plt.axvline(overfit_epoch, color='red', linestyle='--', label=f'Overfit @ {overfit_epoch}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss vs Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(drive_results_path, \"loss_plot.png\"))\n",
    "plt.show()\n",
    "\n",
    "# === PSNR PLOT ===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(psnrs, label='Test PSNR', color='green')\n",
    "plt.axvline(overfit_epoch, color='red', linestyle='--', label=f'Best Epoch: {overfit_epoch}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"PSNR (dB)\")\n",
    "plt.title(\"PSNR vs Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(drive_results_path, \"psnr_plot.png\"))\n",
    "plt.show()\n",
    "\n",
    "# ===Plot SSIM===\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(ssims, label='Test SSIM', color='purple')\n",
    "plt.axvline(overfit_epoch, color='red', linestyle='--', label=f'Best Epoch: {overfit_epoch}')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"SSIM\")\n",
    "plt.title(\"Test SSIM vs Epoch\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(drive_results_path, \"ssim_plot.png\"))\n",
    "plt.show()\n",
    "\n",
    "# === COMPARISON TABLE ===\n",
    "\n",
    "model.load_state_dict(torch.load(\"best_model_4_4.pth\"))\n",
    "model.eval()\n",
    "\n",
    "num_samples = len(test_loader)\n",
    "fig, axes = plt.subplots(num_samples, 3, figsize=(12, 3 * num_samples))\n",
    "if num_samples == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (hazy, clean, hazy_path, clean_path) in enumerate(test_loader):\n",
    "        hazy, clean = hazy.to(device), clean.to(device)\n",
    "        output = model(hazy)\n",
    "\n",
    "        # Convert tensors to image format\n",
    "        dehazed_img_arr = output.squeeze().cpu().numpy().transpose(1, 2, 0)\n",
    "        dehazed_img_arr = (dehazed_img_arr * 255).clip(0, 255).astype(np.uint8)\n",
    "        dehazed_img = Image.fromarray(dehazed_img_arr).resize((256, 256))\n",
    "\n",
    "        hazy_img = Image.open(hazy_path[0]).resize((256, 256))\n",
    "        clean_img = Image.open(clean_path[0]).resize((256, 256))\n",
    "\n",
    "        # Compute metrics\n",
    "        psnr = compare_psnr(clean.cpu().numpy(), output.cpu().numpy(), data_range=1.0)\n",
    "        ssim = compare_ssim(\n",
    "            clean.cpu().squeeze().permute(1, 2, 0).numpy(),\n",
    "            output.cpu().squeeze().permute(1, 2, 0).numpy(),\n",
    "            channel_axis=-1,\n",
    "            data_range=1.0\n",
    "        )\n",
    "\n",
    "        # Plot images\n",
    "        for ax, img, title in zip(\n",
    "            axes[i],\n",
    "            [hazy_img, clean_img, dehazed_img],\n",
    "            [f\"Hazy {i}\", f\"Clean {i}\", f\"Dehazed {i}\\nPSNR: {psnr:.2f}\\nSSIM: {ssim:.4f}\"]\n",
    "        ):\n",
    "            ax.imshow(img)\n",
    "            ax.set_title(title)\n",
    "            ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(drive_results_path, \"comparison_table.png\"))\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Table saved to:\", os.path.join(drive_results_path, \"comparison_table.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16489664-5402-47c5-a4c4-0c8d7414d7c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
