{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca155b1e-c40e-437c-a561-058540ffc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model found at best_model_8_8.pth\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "model_path = \"best_model_8_8.pth\"  # or use the absolute path\n",
    "if not os.path.exists(model_path):\n",
    "    print(f\"Error: The file at {model_path} does not exist.\")\n",
    "else:\n",
    "    print(f\"Model found at {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce1750ae-3c93-4b4e-8ddf-220171836f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Frames: 1340\n",
      "Average FPS: 13.62\n",
      "High-quality video saved to: results/output_video_hq.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "# ------------------- Helper Function -------------------\n",
    "def center_crop(enc_feat, target_size):\n",
    "    _, _, h, w = enc_feat.size()\n",
    "    target_h, target_w = target_size\n",
    "    start_h = (h - target_h) // 2\n",
    "    start_w = (w - target_w) // 2\n",
    "    return enc_feat[:, :, start_h:start_h+target_h, start_w:start_w+target_w]\n",
    "\n",
    "# ------------------- Model Definition -------------------\n",
    "class DeepDehazeNet8Layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DeepDehazeNet8Layer, self).__init__()\n",
    "\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "                nn.BatchNorm2d(out_channels),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Dropout(0.2)\n",
    "            )\n",
    "        self.enc1 = conv_block(3, 64)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.enc2 = conv_block(64, 128)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.enc3 = conv_block(128, 256)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.bottleneck = conv_block(256, 512)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(512, 256, 2, 2)\n",
    "        self.dec1 = conv_block(512, 256)\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, 2, 2)\n",
    "        self.dec2 = conv_block(256, 128)\n",
    "        self.up3 = nn.ConvTranspose2d(128, 64, 2, 2)\n",
    "        self.dec3 = conv_block(128, 64)\n",
    "\n",
    "        self.final = nn.Conv2d(64, 3, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "\n",
    "        u1 = self.up1(b)\n",
    "        e3 = center_crop(e3, u1.shape[2:])\n",
    "        d1 = self.dec1(torch.cat([u1, e3], 1))\n",
    "\n",
    "        u2 = self.up2(d1)\n",
    "        e2 = center_crop(e2, u2.shape[2:])\n",
    "        d2 = self.dec2(torch.cat([u2, e2], 1))\n",
    "\n",
    "        u3 = self.up3(d2)\n",
    "        e1 = center_crop(e1, u3.shape[2:])\n",
    "        d3 = self.dec3(torch.cat([u3, e1], 1))\n",
    "\n",
    "        return torch.sigmoid(self.final(d3))\n",
    "\n",
    "# ------------------- Setup -------------------\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = DeepDehazeNet8Layer().to(device).half()\n",
    "model.load_state_dict(torch.load(\"best_model_8_8.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "video_path = \"input_video.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open video\")\n",
    "\n",
    "resize_dim = (512, 512)\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "frame_count = 0\n",
    "total_infer_time = 0\n",
    "start_time = time.time()\n",
    "\n",
    "video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = resize_dim[0] * 2\n",
    "frame_height = resize_dim[1]\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "output_video_path = os.path.join(\"results\", \"dehazed_output.mp4\")\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, video_fps, (frame_width, frame_height))\n",
    "\n",
    "# For high-quality export\n",
    "hq_frames = []\n",
    "\n",
    "# ------------------- Real-time Processing -------------------\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    frame_resized = cv2.resize(frame, resize_dim)\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    input_tensor = transform(frame_rgb).unsqueeze(0).to(device).half()\n",
    "\n",
    "    infer_start = time.time()\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    infer_end = time.time()\n",
    "\n",
    "    infer_time = infer_end - infer_start\n",
    "    total_infer_time += infer_time\n",
    "    frame_count += 1\n",
    "\n",
    "    output_image = output.squeeze().float().cpu().numpy().transpose(1, 2, 0)\n",
    "    output_image = np.clip(output_image * 255, 0, 255).astype(np.uint8)\n",
    "    output_bgr = cv2.cvtColor(output_image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    fps_current = 1 / infer_time if infer_time > 0 else 0\n",
    "    combined = np.hstack((frame_resized, output_bgr))\n",
    "\n",
    "    # cv2.putText(combined, f\"FPS: {fps_current:.2f}\",\n",
    "                # (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)\n",
    "\n",
    "    out.write(combined)\n",
    "    hq_frames.append(combined)\n",
    "\n",
    "    cv2.imshow(\"Original | Dehazed\", combined)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# ------------------- Final Stats -------------------\n",
    "end_time = time.time()\n",
    "avg_fps = frame_count / (end_time - start_time)\n",
    "avg_infer = (total_infer_time / frame_count) * 1000\n",
    "\n",
    "print(f\"\\nTotal Frames: {frame_count}\")\n",
    "print(f\"Average FPS: {avg_fps:.2f}\")\n",
    "# print(f\"Average Inference Time: {avg_infer:.2f} ms/frame\")\n",
    "\n",
    "# with open(\"results/benchmark_stats.txt\", \"w\") as f:\n",
    "    # f.write(f\"Total Frames: {frame_count}\\n\")\n",
    "    # f.write(f\"Average FPS: {avg_fps:.2f}\\n\")\n",
    "    # f.write(f\"Average Inference Time: {avg_infer:.2f} ms/frame\\n\")\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# ------------------- High-Quality Export -------------------\n",
    "# Export using OpenCV\n",
    "hq_output_path = \"results/output_video_hq.mp4\"\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out_hq = cv2.VideoWriter(hq_output_path, fourcc, video_fps, (frame_width, frame_height))\n",
    "\n",
    "for frame in hq_frames:\n",
    "    out_hq.write(frame)\n",
    "\n",
    "out_hq.release()\n",
    "print(f\"High-quality video saved to: {hq_output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325c75f0-9d8c-46de-9df8-33c7ef4f63d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
